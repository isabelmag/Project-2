{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Load your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conflict = pd.read_csv(\"Project 1_Data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've done something different between this project and Project 1: in Project 1, I split the dataset almost immediately. For Project 2, if I want to be able to identify the target feature, though, I first want to prepare the data, assign the X (all features except 'Battle related deaths') and y (the target, 'Battle related deaths'), and then split along the X and y. This might be entirely wrong, but I've tried it the other way around and couldn't make it work. I've included it at the bottom of a file I've uploaded titled, 'Magnus_Project 1 Update and Project 2', which contains Project 1 corrections/explorations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Prepare your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country Name                                              object\n",
      "Year                                                       int64\n",
      "Adjusted_net_national_income_per_capita__current_US__    float64\n",
      "Death_rate__crude__per_1_000_people_                     float64\n",
      "GDP__current_US__                                        float64\n",
      "GDP_per_capita__current_US__                             float64\n",
      "Military_expenditure__current_USD_                       float64\n",
      "Population_density__people_per_sq__km_of_land_area_      float64\n",
      "Population__total                                        float64\n",
      "Rural_population                                         float64\n",
      "Urban_population                                         float64\n",
      "Battle_related_deaths__number_of_people_                   int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(conflict.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conflict[\"Year\"] = conflict[\"Year\"].astype(\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country Name                                                0\n",
      "Year                                                        0\n",
      "Adjusted_net_national_income_per_capita__current_US__    6531\n",
      "Death_rate__crude__per_1_000_people_                     1465\n",
      "GDP__current_US__                                        3400\n",
      "GDP_per_capita__current_US__                             3403\n",
      "Military_expenditure__current_USD_                       5992\n",
      "Population_density__people_per_sq__km_of_land_area_       872\n",
      "Population__total                                         332\n",
      "Rural_population                                          450\n",
      "Urban_population                                          450\n",
      "Battle_related_deaths__number_of_people_                    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(conflict.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One Hot Encoder of the categorical variables \"Country Name\" and \"Year\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "countryname_enc = pd.get_dummies(conflict[\"Country Name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13440 entries, 0 to 13439\n",
      "Columns: 224 entries, Afghanistan to Zimbabwe\n",
      "dtypes: uint8(224)\n",
      "memory usage: 2.9 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(countryname_enc.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_enc = pd.get_dummies(conflict[\"Year\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13440 entries, 0 to 13439\n",
      "Data columns (total 60 columns):\n",
      "1960    13440 non-null uint8\n",
      "1961    13440 non-null uint8\n",
      "1962    13440 non-null uint8\n",
      "1963    13440 non-null uint8\n",
      "1964    13440 non-null uint8\n",
      "1965    13440 non-null uint8\n",
      "1966    13440 non-null uint8\n",
      "1967    13440 non-null uint8\n",
      "1968    13440 non-null uint8\n",
      "1969    13440 non-null uint8\n",
      "1970    13440 non-null uint8\n",
      "1971    13440 non-null uint8\n",
      "1972    13440 non-null uint8\n",
      "1973    13440 non-null uint8\n",
      "1974    13440 non-null uint8\n",
      "1975    13440 non-null uint8\n",
      "1976    13440 non-null uint8\n",
      "1977    13440 non-null uint8\n",
      "1978    13440 non-null uint8\n",
      "1979    13440 non-null uint8\n",
      "1980    13440 non-null uint8\n",
      "1981    13440 non-null uint8\n",
      "1982    13440 non-null uint8\n",
      "1983    13440 non-null uint8\n",
      "1984    13440 non-null uint8\n",
      "1985    13440 non-null uint8\n",
      "1986    13440 non-null uint8\n",
      "1987    13440 non-null uint8\n",
      "1988    13440 non-null uint8\n",
      "1989    13440 non-null uint8\n",
      "1990    13440 non-null uint8\n",
      "1991    13440 non-null uint8\n",
      "1992    13440 non-null uint8\n",
      "1993    13440 non-null uint8\n",
      "1994    13440 non-null uint8\n",
      "1995    13440 non-null uint8\n",
      "1996    13440 non-null uint8\n",
      "1997    13440 non-null uint8\n",
      "1998    13440 non-null uint8\n",
      "1999    13440 non-null uint8\n",
      "2000    13440 non-null uint8\n",
      "2001    13440 non-null uint8\n",
      "2002    13440 non-null uint8\n",
      "2003    13440 non-null uint8\n",
      "2004    13440 non-null uint8\n",
      "2005    13440 non-null uint8\n",
      "2006    13440 non-null uint8\n",
      "2007    13440 non-null uint8\n",
      "2008    13440 non-null uint8\n",
      "2009    13440 non-null uint8\n",
      "2010    13440 non-null uint8\n",
      "2011    13440 non-null uint8\n",
      "2012    13440 non-null uint8\n",
      "2013    13440 non-null uint8\n",
      "2014    13440 non-null uint8\n",
      "2015    13440 non-null uint8\n",
      "2016    13440 non-null uint8\n",
      "2017    13440 non-null uint8\n",
      "2018    13440 non-null uint8\n",
      "2019    13440 non-null uint8\n",
      "dtypes: uint8(60)\n",
      "memory usage: 787.6 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(year_enc.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imputer using the strategy = mean for the continuous variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python\\lib\\site-packages\\sklearn\\utils\\deprecation.py:66: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "imputer = Imputer(strategy=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "conflict_num = conflict.drop(\"Country Name\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "conflict_num = conflict_num.drop(\"Year\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13440 entries, 0 to 13439\n",
      "Data columns (total 10 columns):\n",
      "Adjusted_net_national_income_per_capita__current_US__    6909 non-null float64\n",
      "Death_rate__crude__per_1_000_people_                     11975 non-null float64\n",
      "GDP__current_US__                                        10040 non-null float64\n",
      "GDP_per_capita__current_US__                             10037 non-null float64\n",
      "Military_expenditure__current_USD_                       7448 non-null float64\n",
      "Population_density__people_per_sq__km_of_land_area_      12568 non-null float64\n",
      "Population__total                                        13108 non-null float64\n",
      "Rural_population                                         12990 non-null float64\n",
      "Urban_population                                         12990 non-null float64\n",
      "Battle_related_deaths__number_of_people_                 13440 non-null int64\n",
      "dtypes: float64(9), int64(1)\n",
      "memory usage: 1.0 MB\n"
     ]
    }
   ],
   "source": [
    "conflict_num.shape\n",
    "conflict_num.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Imputer(axis=0, copy=True, missing_values='NaN', strategy='mean', verbose=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer.fit(conflict_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.38708204e+03, 1.05395572e+01, 3.66643775e+11, 8.45537928e+03,\n",
       "       1.31439113e+10, 3.19506808e+02, 3.11112350e+07, 1.51191263e+07,\n",
       "       1.62673031e+07, 1.04845313e+02])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer.statistics_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.38708204e+03, 1.05395572e+01, 3.66643775e+11, 8.45537928e+03,\n",
       "       1.31439113e+10, 3.19506808e+02, 3.11112350e+07, 1.51191263e+07,\n",
       "       1.62673031e+07, 1.04845313e+02])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conflict_num.mean().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = imputer.transform(conflict_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "conflict = pd.DataFrame(X, columns=conflict_num.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13440 entries, 0 to 13439\n",
      "Data columns (total 10 columns):\n",
      "Adjusted_net_national_income_per_capita__current_US__    13440 non-null float64\n",
      "Death_rate__crude__per_1_000_people_                     13440 non-null float64\n",
      "GDP__current_US__                                        13440 non-null float64\n",
      "GDP_per_capita__current_US__                             13440 non-null float64\n",
      "Military_expenditure__current_USD_                       13440 non-null float64\n",
      "Population_density__people_per_sq__km_of_land_area_      13440 non-null float64\n",
      "Population__total                                        13440 non-null float64\n",
      "Rural_population                                         13440 non-null float64\n",
      "Urban_population                                         13440 non-null float64\n",
      "Battle_related_deaths__number_of_people_                 13440 non-null float64\n",
      "dtypes: float64(10)\n",
      "memory usage: 1.0 MB\n"
     ]
    }
   ],
   "source": [
    "conflict.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bringing the One Hot Coded variables back together with the continuous variables, first by resetting the indexes so they don't mismatch and introduce NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "countryname_enc.reset_index(drop=True, inplace=True)\n",
    "year_enc.reset_index(drop=True, inplace=True)\n",
    "conflict.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalconflicttrain = countryname_enc.join(year_enc, on=None, how='left', lsuffix='', rsuffix='', sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "conflictnp = finalconflicttrain.join(conflict, on=None, how='left', lsuffix='', rsuffix='', sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13440, 294)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conflictnp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "conflictnp[\"Battle_related_deaths__number_of_people_\"].hist(bins=50, figsize=(20,15)) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable 'Battle Related Deaths' is neither Guassian nor normal; it is heavily right-skewed, with a majority of the observations having a value of 0 (please see some value counts below). While I explored a logarithmic variable of 'Battle related deaths' in Project 1 and would also like to do so here to compare/contrast train/test scores between the two, I'm just going to start with the original, non-normalized observations provided. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0       12491\n",
       "50.0         16\n",
       "25.0         15\n",
       "1.0          11\n",
       "2.0          10\n",
       "          ...  \n",
       "997.0         1\n",
       "6052.0        1\n",
       "4071.0        1\n",
       "495.0         1\n",
       "1173.0        1\n",
       "Name: Battle_related_deaths__number_of_people_, Length: 631, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conflict_df['Battle_related_deaths__number_of_people_'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Select your target attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I struggled with this for the longest time (and I still may have done it incorrectly) because I forgot the basics of splicing :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "conflict_df = pd.DataFrame(data=conflictnp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13440, 294)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conflict_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "conflictnp = conflict_df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = conflictnp[:, 0:293]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13440, 293)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = pd.DataFrame(data=X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = conflictnp[:, 293]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13440,)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I believe I figured out StratifiedSplit for Project 1 and I know we were supposed to just bring that directly over but I've gotten wildly confused about the different ways to split the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4a: Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.12\n",
      "Test set score: 0.09\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set score: {:.2f}\".format(lr.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(lr.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, so pretty horrible scores on both the training and test sets, indicating underfitting. It's important to note that I haven't scaled my inputs! My features' distributions are not all Gaussian, either - two factors that would probably result in better-performing linear regression models. There's also probably a ton of noise in this data, and certain variables (like total population, urban population, and rural population) are certainly correlated/lacking independence. Now, allow me to proceed with what is more and more apparently the inappropriate type of model for my dataset!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5a: Tuning, cross-validation, r2, RMSE, and MAE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 249.73652767277756\n",
      "Mean Squared Error: 3023186.6552968314\n",
      "Root Mean Squared Error: 1738.7313349959595\n"
     ]
    }
   ],
   "source": [
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The large MAE, 250, indicates that my model is not very good at making predictions. The MSE and RMSE are both measures of fit. The RMSE, as the standard deviation of the prediction errors, is a measure of how far the data points are from the regression line. With an RMSE = 1739, we can safely say this is a very bad fit.I'm wondering, actually, if these numbers should be read in context of the range of the variable 'Battle related deaths', which has a range from 0 to ~7,000.\n",
    "\n",
    "\n",
    "I'm now going to run a linear regression model using cross validation. Because of the size of the dataset, I might have been well served by using shuffle split validation. Hopefully, the cross validation will minimize any of the bias I may have introduced by not using a balanced train/test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [-0.08612662 -0.48286207  0.00362175]\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(lr, X, y)\n",
    "print(\"Cross-validation scores: {}\".format(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy results of my default 3-fold cross validation are negative!Which I did not realize they could be. I have to research this, because I don't understand what that means. It seems I do even more poorly when I increase the number of folds to 5 below. The average of scores = -0.19 while the average of scores2 = -16.03. I'm assuming that the farther away from 0 in a negative direction means I've done worse. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [-1.41736886e-01 -7.96222661e+01 -2.93113384e-01 -7.22578394e-02\n",
      " -2.47696443e-04]\n"
     ]
    }
   ],
   "source": [
    "scores2 = cross_val_score(lr, X, y, cv=5) \n",
    "print(\"Cross-validation scores: {}\".format(scores2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cross-validation score: -16.03\n"
     ]
    }
   ],
   "source": [
    "print(\"Average cross-validation score: {:.2f}\".format(scores2.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to try a Ridge regression (L2 Penalty) to explore more/less robust regularization in the model -- Ridge is a tradeoff between model simplicity and model performance. Because I am already doing so poorly (underfitting, which means the model is too simple), I don't believe Ridge is going to help me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.12\n",
      "Test set score: 0.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=2.17125e-29): result may not be accurate.\n",
      "  overwrite_a=True).T\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge = Ridge().fit(X_train, y_train)\n",
    "print(\"Training set score: {:.2f}\".format(ridge.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(ridge.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.12\n",
      "Test set score: 0.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=1.90691e-28): result may not be accurate.\n",
      "  overwrite_a=True).T\n"
     ]
    }
   ],
   "source": [
    "ridge10 = Ridge(alpha=10).fit(X_train, y_train)\n",
    "print(\"Training set score: {:.2f}\".format(ridge10.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(ridge10.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.12\n",
      "Test set score: 0.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=2.23307e-30): result may not be accurate.\n",
      "  overwrite_a=True).T\n"
     ]
    }
   ],
   "source": [
    "ridge01 = Ridge(alpha=0.1).fit(X_train, y_train)\n",
    "print(\"Training set score: {:.2f}\".format(ridge01.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(ridge01.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.12\n",
      "Test set score: 0.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=2.24092e-31): result may not be accurate.\n",
      "  overwrite_a=True).T\n"
     ]
    }
   ],
   "source": [
    "ridge001 = Ridge(alpha=0.01).fit(X_train, y_train)\n",
    "print(\"Training set score: {:.2f}\".format(ridge001.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(ridge001.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing alpha moves more coefficients towards 0. My ridge models perform almost identically to my plain linear regression model, with a higher alpha slightly worsening the test set score. \n",
    "\n",
    "I'm now going to try using Lasso regression (L1 Penalty). In these models, if alpha is too high it will 0 out too many coefficients; an alpha value that is too low will result in a model that is effectively unregularized. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.12\n",
      "Test set score: 0.09\n",
      "Number of features used: 62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6280020955.091457, tolerance: 1382997.0722099077\n",
      "  positive)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso = Lasso().fit(X_train, y_train)\n",
    "print(\"Training set score: {:.2f}\".format(lasso.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(lasso.score(X_test, y_test)))\n",
    "print(\"Number of features used:\", np.sum(lasso.coef_ != 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.12\n",
      "Test set score: 0.09\n",
      "Number of features used: 285\n"
     ]
    }
   ],
   "source": [
    "# we increase the default setting of \"max_iter\",\n",
    "# otherwise the model would warn us that we should increase max_iter.\n",
    "lasso001 = Lasso(alpha=0.01, max_iter=100000).fit(X_train, y_train)\n",
    "print(\"Training set score: {:.2f}\".format(lasso001.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(lasso001.score(X_test, y_test)))\n",
    "print(\"Number of features used:\", np.sum(lasso001.coef_ != 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.12\n",
      "Test set score: 0.09\n",
      "Number of features used: 292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6062598523.974706, tolerance: 1382997.0722099077\n",
      "  positive)\n"
     ]
    }
   ],
   "source": [
    "lasso00001 = Lasso(alpha=0.0001, max_iter=100000).fit(X_train, y_train)\n",
    "print(\"Training set score: {:.2f}\".format(lasso00001.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(lasso00001.score(X_test, y_test)))\n",
    "print(\"Number of features used:\", np.sum(lasso00001.coef_ != 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.00\n",
      "Test set score: 0.00\n",
      "Number of features used: 8\n"
     ]
    }
   ],
   "source": [
    "lasso100 = Lasso(alpha=100, max_iter=100000).fit(X_train, y_train)\n",
    "print(\"Training set score: {:.2f}\".format(lasso100.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(lasso100.score(X_test, y_test)))\n",
    "print(\"Number of features used:\", np.sum(lasso100.coef_ != 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.04\n",
      "Test set score: 0.02\n",
      "Number of features used: 12\n"
     ]
    }
   ],
   "source": [
    "lasso10 = Lasso(alpha=10, max_iter=100000).fit(X_train, y_train)\n",
    "print(\"Training set score: {:.2f}\".format(lasso10.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(lasso10.score(X_test, y_test)))\n",
    "print(\"Number of features used:\", np.sum(lasso10.coef_ != 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have not achieved train/test scores that are any better by using Lasso.I still have a model that's really underfitting. With Lasso, I can adjust both the alpha values (significance of coefficients) and the max_iteration value (INSERT). When I decreased alpha, the model used almost all of the features (i.e. it's almost completely unregularized when it's considering 292 out of 294 features). When I dramatically increase the alpha to 100, the model zeroes out too many coefficients, using only 8 features and returning the worst possible train/test scores - 0. I didn't expect to do better with Lasso than I did with Ridge, but it has been curious to see the slight differences in resulting scores - it would appear that a completely unregularized Lasso performs better than a Lasso with an alpha as high as 10!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4b: Decision Trees and Forests+"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think I will have much more success with trees because trees look at variables and say, come as you are. You don't need to normalize, you don't need to standard scale. Trees have the tendency to overfit, which I'm excited about considering the linear model was so underfitted. Let's see if I need to consider pre/post-pruning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeRegressor(max_depth=3).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.346\n",
      "Accuracy on test set: 0.504\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on training set: {:.3f}\".format(tree.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(tree.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can't tell you how relieved I am to see a test score higher than 0.09. I know 0.504 is not a great score, but also consider that this is a very simple tree with a max_depth of only 3. I'm imagining this would be a very interpretable visualization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree R^2: 0.50\n",
      "Decision Tree RMSE: 1651270.46\n"
     ]
    }
   ],
   "source": [
    "print(\"Decision Tree R^2: {:.2f}\".format(tree.score(X_test, y_test)))\n",
    "print(\"Decision Tree RMSE: {:.2f}\".format(mean_squared_error(y_test, tree.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm curious about the huge difference between the tree's R^2 and the tree's RMSE. If R^2 is explained variation/total variation, then this is saying that the model explains half of the variability of the response data around its mean.BUT, the RMSE being so high also makes it seem that this isn't a very good fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importances:\n",
      "[0.13019697 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.05318857 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.06157263 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.05249598 0.         0.\n",
      " 0.43662012 0.         0.25226383 0.01366189 0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature importances:\\n{}\".format(tree.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'sklearn.tree' has no attribute 'feature_importances_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-100-07df912ad2b5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mplot_feature_importances_cancer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-100-07df912ad2b5>\u001b[0m in \u001b[0;36mplot_feature_importances_cancer\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mplot_feature_importances_cancer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbarh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malign\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'center'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myticks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Feature importance\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'sklearn.tree' has no attribute 'feature_importances_'"
     ]
    }
   ],
   "source": [
    "################ I can't figure out how to put this in the nice chart, which makes interpreting it impossible\n",
    "def plot_feature_importances_cancer(model):\n",
    "    n_features = X.shape[1]\n",
    "    plt.barh(np.arange(n_features), model.feature_importances_, align='center')\n",
    "    plt.yticks(np.arange(n_features), X_df.feature_names)\n",
    "    plt.xlabel(\"Feature importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    plt.ylim(-1, n_features)\n",
    "\n",
    "plot_feature_importances_cancer(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'sklearn.tree' has no attribute 'feature_importances_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-98-4d0b9696f72b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot_feature_importances_cancer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-96-bb06399220d0>\u001b[0m in \u001b[0;36mplot_feature_importances_cancer\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mplot_feature_importances_cancer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbarh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malign\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'center'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myticks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Feature importance\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'sklearn.tree' has no attribute 'feature_importances_'"
     ]
    }
   ],
   "source": [
    "######plot_feature_importances_cancer(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it seems like we're on the right track here with the decision trees. Time to explore a little more!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5b: Decision Tree Tuning Parameters and Forest Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By setting a larger max depth, I give my tree more room to grow in complexity before it finds the best leaves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree2 = DecisionTreeRegressor(max_depth=5).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.787\n",
      "Accuracy on test set: 0.801\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on training set: {:.3f}\".format(tree2.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(tree2.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree R^2: 0.80\n",
      "Decision Tree RMSE: 664428.63\n"
     ]
    }
   ],
   "source": [
    "print(\"Decision Tree R^2: {:.2f}\".format(tree2.score(X_test, y_test)))\n",
    "print(\"Decision Tree RMSE: {:.2f}\".format(mean_squared_error(y_test, tree2.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! With more depth, I have better accuracy scores, a higher R^2, and a lower RMSE (it was >1,000,000 before).\n",
    "\n",
    "I'm going to see what kind of luck I have with forests now. The forest is less easily interpretable but because it creates many trees and averages their scores, I'm hoping it will result in higher accuracy scores for both train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=10,\n",
       "                      max_features='auto', max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=5, n_jobs=None,\n",
       "                      oob_score=False, random_state=2, verbose=0,\n",
       "                      warm_start=False)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest = RandomForestRegressor(max_depth = 10, n_estimators=5, random_state=2)\n",
    "forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.804\n",
      "Accuracy on test set: 0.578\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on training set: {:.3f}\".format(forest.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(forest.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, the forest increased accuracy on my training set and decreased accuracy on my test set, which makes me think it overfit to the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'feature_names'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-101-5383cb10e09e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot_feature_importances_cancer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mforest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-100-07df912ad2b5>\u001b[0m in \u001b[0;36mplot_feature_importances_cancer\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbarh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malign\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'center'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myticks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Feature importance\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Feature\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5177\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5178\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5179\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5181\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'feature_names'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##wish I could figure this out\n",
    "plot_feature_importances_cancer(forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=10,\n",
       "                      max_features='auto', max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                      n_jobs=None, oob_score=False, random_state=2, verbose=0,\n",
       "                      warm_start=False)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest2 = RandomForestRegressor(max_depth = 10, n_estimators=100, random_state=2)\n",
    "forest2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.854\n",
      "Accuracy on test set: 0.343\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on training set: {:.3f}\".format(forest2.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(forest2.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My first forest didn't perform as well as my tree with max_depth = 5. I wondered if it was because I had a small number of estimators, so I made a second forest with a much higher number of estimators (100) which did a bit better on the training set but even worse on the test set.\n",
    "\n",
    "I'm curious about Gradient Boosted trees and how well they'll model the data, with each shallow tree correcting the mistakes of the previous tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 1.000\n",
      "Accuracy on test set: 0.921\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gbrt = GradientBoostingClassifier(n_estimators=100, random_state=0)\n",
    "gbrt.fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy on training set: {:.3f}\".format(gbrt.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(gbrt.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! I guess this is my best model, huh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.017\n",
      "Accuracy on test set: 0.012\n"
     ]
    }
   ],
   "source": [
    "gbrt1 = GradientBoostingClassifier(random_state=0, max_depth=1)\n",
    "gbrt1.fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy on training set: {:.3f}\".format(gbrt1.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(gbrt1.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.006\n",
      "Accuracy on test set: 0.004\n"
     ]
    }
   ],
   "source": [
    "gbrt2 = GradientBoostingClassifier(n_estimators=10,random_state=0, learning_rate=0.9)\n",
    "gbrt2.fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy on training set: {:.3f}\".format(gbrt2.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(gbrt2.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The three of these GBRTs took about 10 hours to run, so that was fun to experience! I seem to have found a sweet spot with n_estimators=100, random_state=0, (and a default learning_rate=0.1) with the highest accuracy scores for both the train and test set. I am overfitting, however, and I'd like to try a lower learning rate to see how that works.\n",
    "\n",
    "\n",
    "The other two trees did not perform well, and here are some reasons why that might be:\n",
    "The learning_rate controls how strongly each tree tries to correct the previous tree. It's possible I should have used a higher learning rate so the trees could make stronger corrections.\n",
    "\n",
    "While gradient boosted regression trees function on the concept that many shallower (i.e weaker trees) will be able to correct one another and provide the strongest accuracy, a max_depth of 1 is way too shallow to get anything done!\n",
    "\n",
    "The higher n_estimators worked well because it adds more trees to the ensemble and increases model complexity. Only 10 trees with such a low learning rate? Wasn't going to help me!\n",
    "\n",
    "I'm adding in one final gradient boosted tree below to see if I can do any better than my first one - I'm not sure I'll have the time before submission! But we'll see! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 1.000\n",
      "Accuracy on test set: 0.921\n"
     ]
    }
   ],
   "source": [
    "gbrt3 = GradientBoostingClassifier(n_estimators=100, random_state=0, learning_rate=0.01)\n",
    "gbrt3.fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy on training set: {:.3f}\".format(gbrt3.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(gbrt3.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No, it did the same on its accuracy scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given what I knew about the dataset and what I had done in preprocessing it, deciding to work with linear regression models didn't really make a lot of sense!\n",
    "\n",
    "Decision trees and forests, based on their assumptions, made much more sense and provided much better accuracy results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
